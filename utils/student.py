"""
    Purpose: how to serving the student model (model serving plan). For example, deploy multi LLMs models in production
    Consider: LoRA is solution of the shared resources serving fine-tunes models per GPU
            LoRA is a kind of parameter-efficient fine-tuning technique (PEFT)
                Extended - LoRA exchange (LoRAX)  

"""